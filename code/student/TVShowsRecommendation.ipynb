{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tv_recommendation import TVRecommendationEngine\n",
    "from evaluation_metrics import RecommendationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of R: (9985, 563)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "engine = TVRecommendationEngine()\n",
    "# TODO: Load data\n",
    "engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "print(f\"shape of R: {engine.R.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user degree matrix P has shape (9985, 9985)\n",
      "item degree matrix Q has shape: (563, 563)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# TODO: Preprocess data\n",
    "engine.preprocess_data()\n",
    "print(f\"user degree matrix P has shape {engine.P.shape}\")\n",
    "print(f\"item degree matrix Q has shape: {engine.Q.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated missing data for user 499 Alex\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "ALEX_USER_ID = 499\n",
    "# TODO: Simulate missing data for first 100 shows\n",
    "missing_indices = list(range(100))\n",
    "\n",
    "R_alex_original = engine.R[ALEX_USER_ID, :].copy()\n",
    "engine.R[ALEX_USER_ID, missing_indices] = 0\n",
    "\n",
    "print(f\"simulated missing data for user {ALEX_USER_ID} Alex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "# TODO: User-user collaborative filtering\n",
    "uu_scores = engine.user_user_collaborative_filtering(ALEX_USER_ID, missing_indices)\n",
    "uu_recommendations = engine.get_top_recommendations(uu_scores, missing_indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "# TODO: Item-item collaborative filtering\n",
    "ii_scores = engine.item_item_collaborative_filtering(ALEX_USER_ID, missing_indices)\n",
    "ii_recommendations = engine.get_top_recommendations(ii_scores, missing_indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User CF recommendations:\n",
      "1. \"FOX 28 News at 10pm\" (score: 908.48)\n",
      "2. \"Family Guy\" (score: 861.18)\n",
      "3. \"2009 NCAA Basketball Tournament\" (score: 827.60)\n",
      "4. \"NBC 4 at Eleven\" (score: 784.78)\n",
      "5. \"Two and a Half Men\" (score: 757.60)\n",
      "\n",
      "Item-Item CF recommendations:\n",
      "1. \"FOX 28 News at 10pm\" (score: 31.36)\n",
      "2. \"Family Guy\" (score: 30.00)\n",
      "3. \"NBC 4 at Eleven\" (score: 29.40)\n",
      "4. \"2009 NCAA Basketball Tournament\" (score: 29.23)\n",
      "5. \"Access Hollywood\" (score: 28.97)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7\n",
    "# TODO: Display results\n",
    "print(\"User-User CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(uu_recommendations):\n",
    "    print(f\"{i+1}. {name} (score: {score:.2f})\")\n",
    "\n",
    "print(\"\\nItem-Item CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(ii_recommendations):\n",
    "    print(f\"{i+1}. {name} (score: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User CF max score: 908.48 (requirement: > 900) ✓\n",
      "Item-Item CF max score: 31.36 (requirement: > 31) ✓\n",
      "All requirements passed!\n",
      "User-User recommendations: 5\n",
      "Item-Item recommendations: 5\n",
      "Overlap: 4\n",
      "Unique to User-User: 1\n",
      "Unique to Item-Item: 1\n",
      "Common recommendations:\n",
      "  - \"FOX 28 News at 10pm\"\n",
      "  - \"Family Guy\"\n",
      "  - \"2009 NCAA Basketball Tournament\"\n",
      "  - \"NBC 4 at Eleven\"\n",
      "\n",
      "Experiment Summary:\n",
      "Target User: 499 (Alex)\n",
      "Missing Items: First 100 shows\n",
      "User-User CF Max Score: 908.48\n",
      "Item-Item CF Max Score: 31.36\n",
      "Recommendations overlap: 4/5\n"
     ]
    }
   ],
   "source": [
    "# Cell 8\n",
    "evaluator = RecommendationEvaluator()\n",
    "\n",
    "uu_max_score = uu_recommendations[0][1] if uu_recommendations else 0\n",
    "ii_max_score = ii_recommendations[0][1] if ii_recommendations else 0\n",
    "evaluator.validate_requirements(uu_max_score, ii_max_score)\n",
    "overlap = evaluator.analyze_recommendations(uu_recommendations, ii_recommendations)\n",
    "\n",
    "\n",
    "print(f\"\\nExperiment Summary:\")\n",
    "print(f\"Target User: {ALEX_USER_ID} (Alex)\")\n",
    "print(f\"Missing Items: First 100 shows\")\n",
    "print(f\"User-User CF Max Score: {uu_max_score:.2f}\")\n",
    "print(f\"Item-Item CF Max Score: {ii_max_score:.2f}\")\n",
    "print(f\"Recommendations overlap: {len(overlap)}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Ratings matrix R has shape: (9985, 563)\n",
      "\n",
      "--- Dataset Sparsity Analysis ---\n",
      "Total ratings (1s): 758878\n",
      "Missing ratings (0s): 4862677\n",
      "Total possible ratings: 5621555\n",
      "Sparsity of the matrix: 86.50%\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "engine = TVRecommendationEngine()\n",
    "# TODO: Load data\n",
    "engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "print(f\"Data loaded successfully.\")\n",
    "print(f\"Ratings matrix R has shape: {engine.R.shape}\")\n",
    "\n",
    "num_ones = np.sum(engine.R)\n",
    "\n",
    "total_elements=engine.R.size\n",
    "\n",
    "num_zeros=total_elements - num_ones\n",
    "\n",
    "sparsity=(num_zeros / total_elements) *100\n",
    "\n",
    "print(f\"\\n--- Dataset Sparsity Analysis ---\")\n",
    "print(f\"Total ratings (1s): {num_ones}\")\n",
    "print(f\"Missing ratings (0s): {num_zeros}\")\n",
    "print(f\"Total possible ratings: {total_elements}\")\n",
    "print(f\"Sparsity of the matrix: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Cosine Similairty Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Cosine Similarity Calculations (with Refined Timing) ---\n",
      "\n",
      "Verification for User Similarity Matrix (Su):\n",
      "  Time taken (Our Formula):   41.8253 seconds\n",
      "  Time taken (sklearn):       3.6006 seconds\n",
      "  Maximum absolute difference:      2.11e-15\n",
      "\n",
      "Verification for Item Similarity Matrix (Si):\n",
      "  Time taken (Our Formula):   0.4403 seconds\n",
      "  Time taken (sklearn):       0.1985 seconds\n",
      "  Maximum absolute difference:      2.66e-15\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "print(\"--- Verifying Cosine Similarity Calculations (with Refined Timing) ---\")\n",
    "\n",
    "temp_engine = TVRecommendationEngine()\n",
    "temp_engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "temp_engine.preprocess_data()\n",
    "R_matrix = temp_engine.R\n",
    "P_matrix = temp_engine.P\n",
    "Q_matrix = temp_engine.Q\n",
    "\n",
    "start_time_formula = time.time()\n",
    "Su_formula = temp_engine.sim_computer.compute_user_similarity_matrix(R_matrix, P_matrix)\n",
    "end_time_formula = time.time()\n",
    "time_formula_user = end_time_formula - start_time_formula\n",
    "\n",
    "start_time_sklearn = time.time()\n",
    "Su_sklearn = cosine_similarity(R_matrix)\n",
    "end_time_sklearn = time.time()\n",
    "time_sklearn_user = end_time_sklearn - start_time_sklearn\n",
    "\n",
    "user_diff =np.abs(Su_formula - Su_sklearn)\n",
    "\n",
    "print(\"\\nVerification for User Similarity Matrix (Su):\")\n",
    "print(f\" Time taken (Our Formula):   {time_formula_user:.4f} seconds\")\n",
    "print(f\" Time taken (sklearn):     {time_sklearn_user:.4f} seconds\")\n",
    "print(f\" Maximum absolute difference:      {np.max(user_diff):.2e}\")\n",
    "\n",
    "\n",
    "start_time_formula = time.time()\n",
    "Si_formula = temp_engine.sim_computer.compute_item_similarity_matrix(R_matrix, Q_matrix)\n",
    "end_time_formula = time.time()\n",
    "time_formula_item = end_time_formula - start_time_formula\n",
    "\n",
    "start_time_sklearn = time.time()\n",
    "Si_sklearn = cosine_similarity(R_matrix.T)\n",
    "end_time_sklearn = time.time()\n",
    "time_sklearn_item = end_time_sklearn - start_time_sklearn\n",
    "\n",
    "item_diff = np.abs(Si_formula - Si_sklearn)\n",
    "\n",
    "print(\"\\nVerification for Item Similarity Matrix (Si):\")\n",
    "print(f\"  Time taken (Our Formula):   {time_formula_item:.4f} seconds\")\n",
    "print(f\"  Time taken (sklearn):     {time_sklearn_item:.4f} seconds\")\n",
    "print(f\"  Maximum absolute difference:      {np.max(item_diff):.2e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Precision & recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Alex had 0 relevant shows in the hidden test set.\n",
      "\n",
      "--- User-User CF Evaluation ---\n",
      "  Hits (correct recommendations): 0 out of 5\n",
      "  Precision@5: 0.00\n",
      "  Recall@5:    0.00\n",
      "\n",
      "--- Item-Item CF Evaluation ---\n",
      "  Hits (correct recommendations): 0 out of 5\n",
      "  Precision@5: 0.00\n",
      "  Recall@5:    0.00\n"
     ]
    }
   ],
   "source": [
    "relevant_items={i for i, rating in enumerate(R_alex_original[:100]) if rating == 1}\n",
    "num_relevant_items=len(relevant_items)\n",
    "\n",
    "print(f\"Alex had {num_relevant_items} relevant shows in the hidden test set.\")\n",
    "\n",
    "recommended_uu={idx for idx, score, name in uu_recommendations}\n",
    "recommended_ii= {idx for idx, score, name in ii_recommendations}\n",
    "\n",
    "hits_uu = len(relevant_items.intersection(recommended_uu))\n",
    "\n",
    "precision_uu = hits_uu /5\n",
    "\n",
    "recall_uu = hits_uu /num_relevant_items if num_relevant_items >0 else 0\n",
    "\n",
    "print(\"\\n--- User-User CF Evaluation ---\")\n",
    "print(f\"  Hits (correct recommendations): {hits_uu} out of 5\")\n",
    "print(f\"  Precision@5: {precision_uu:.2f}\")\n",
    "print(f\"  Recall@5:    {recall_uu:.2f}\")\n",
    "\n",
    "hits_ii = len(relevant_items.intersection(recommended_ii))\n",
    "\n",
    "precision_ii = hits_ii / 5\n",
    "recall_ii = hits_ii / num_relevant_items if num_relevant_items > 0 else 0\n",
    "\n",
    "print(\"\\n--- Item-Item CF Evaluation ---\")\n",
    "print(f\"  Hits (correct recommendations): {hits_ii} out of 5\")\n",
    "print(f\"  Precision@5: {precision_ii:.2f}\")\n",
    "print(f\"  Recall@5:    {recall_ii:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully loaded the original ratings matrix of shape: (9985, 563)\n",
      "\n",
      "--- Full Original Viewing History for Alex (user index 499) ---\n",
      "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0,\n",
      "       0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1,\n",
      "       1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0,\n",
      "       1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1,\n",
      "       1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0,\n",
      "       0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1,\n",
      "       0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0])\n",
      "\n",
      "--- Verification Summary ---\n",
      "Number of shows Alex watched in the first 100 items: 0\n",
      "\n",
      "CONCLUSION: The output is correct. Alex had 0 watched shows in the test set.\n"
     ]
    }
   ],
   "source": [
    "user_shows_path = 'data/user-shows.txt'\n",
    "\n",
    "ALEX_USER_ID = 499\n",
    "\n",
    "R_original=np.loadtxt(user_shows_path, dtype=int)\n",
    "print(f\"Successfully loaded the original ratings matrix of shape: {R_original.shape}\\n\")\n",
    "\n",
    "if ALEX_USER_ID < R_original.shape[0]:\n",
    "    alex_original_row = R_original[ALEX_USER_ID, :]\n",
    "    print(f\"--- Full original viewing history for alex (user index {ALEX_USER_ID}) ---\")\n",
    "    print(repr(alex_original_row))\n",
    "    shows_watched_in_first_100=np.sum(alex_original_row[:100])\n",
    "    \n",
    "    print(\"\\n--- Verification Summary ---\")\n",
    "    print(f\"Number of shows Alex watched in the first 100 items: {shows_watched_in_first_100}\")\n",
    "\n",
    "    if shows_watched_in_first_100 == 0:\n",
    "        print(\"\\nCONCLUSION: The output is correct. Alex had 0 watched shows in the test set.\")\n",
    "    else:\n",
    "        print(\"\\nCONCLUSION: There is a discrepancy. The data shows Alex did watch shows in this range.\")\n",
    "\n",
    "else:\n",
    "    print(f\"Error: Alex's user ID ({ALEX_USER_ID}) is out of bounds for the matrix.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using a new user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Running Full Analysis for a New User (User 3) ---\n",
      "Targeting new user with index: 4\n",
      "\n",
      "Running User-User and Item-Item CF for User 3...\n",
      "\n",
      "--- Top 5 Recommendations for User 3 ---\n",
      "\n",
      "User-User CF recommendations:\n",
      "1. \"Family Guy\" (Score: 293.23)\n",
      "2. \"2009 NCAA Basketball Tournament\" (Score: 282.96)\n",
      "3. \"FOX 28 News at 10pm\" (Score: 282.85)\n",
      "4. \"Access Hollywood\" (Score: 264.77)\n",
      "5. \"NBC 4 at Eleven\" (Score: 252.21)\n",
      "\n",
      "Item-Item CF recommendations:\n",
      "1. \"Family Guy\" (Score: 4.22)\n",
      "2. \"2009 NCAA Basketball Tournament\" (Score: 4.15)\n",
      "3. \"SportsCenter\" (Score: 4.13)\n",
      "4. \"FOX 28 News at 10pm\" (Score: 4.03)\n",
      "5. \"Access Hollywood\" (Score: 3.97)\n",
      "\n",
      "--- Quantitative Evaluation for User 3: Precision & Recall @ 5 ---\n",
      "User 3 had 9 relevant shows in the hidden test set.\n",
      "\n",
      "--- User-User CF Evaluation (User 3) ---\n",
      "  Hits (correct recommendations): 0 out of 5\n",
      " Precision@5: 0.00\n",
      "  Recall@5:  0.00\n",
      "\n",
      "--- Item-Item CF Evaluation (User 3) ---\n",
      " Hits (correct recommendations): 1 out of 5\n",
      " Precision@5: 0.20\n",
      " Recall@5:  0.11\n"
     ]
    }
   ],
   "source": [
    "print(\"--- Running Full Analysis for a New User (User 3) ---\")\n",
    "\n",
    "engine_user3= TVRecommendationEngine()\n",
    "engine_user3.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "engine_user3.preprocess_data()\n",
    "\n",
    "NEW_USER_ID=3\n",
    "print(f\"Targeting new user with index: {NEW_USER_ID}\")\n",
    "\n",
    "missing_indices=list(range(100))\n",
    "\n",
    "R_user3_original =engine_user3.R[NEW_USER_ID,:].copy()\n",
    "engine_user3.R[NEW_USER_ID, missing_indices] = 0\n",
    "\n",
    "print(\"\\nRunning User-User and Item-Item CF for User 3...\")\n",
    "uu_scores_user3=engine_user3.user_user_collaborative_filtering(NEW_USER_ID, missing_indices)\n",
    "uu_recs_user3=engine_user3.get_top_recommendations(uu_scores_user3, missing_indices, 5)\n",
    "\n",
    "ii_scores_user3=engine_user3.item_item_collaborative_filtering(NEW_USER_ID, missing_indices)\n",
    "ii_recs_user3=engine_user3.get_top_recommendations(ii_scores_user3, missing_indices, 5)\n",
    "\n",
    "print(\"\\n--- Top 5 Recommendations for User 3 ---\")\n",
    "print(\"\\nUser-User CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(uu_recs_user3):\n",
    "    print(f\"{i+1}. {name} (Score: {score:.2f})\")\n",
    "\n",
    "print(\"\\nItem-Item CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(ii_recs_user3):\n",
    "    print(f\"{i+1}. {name} (Score: {score:.2f})\")\n",
    "    \n",
    "print(\"\\n--- Quantitative Evaluation for User 3: Precision & Recall @ 5 ---\")\n",
    "\n",
    "relevant_items_user3={i for i, rating in enumerate(R_user3_original[:100]) if rating == 1}\n",
    "num_relevant_user3=len(relevant_items_user3)\n",
    "print(f\"User 3 had {num_relevant_user3} relevant shows in the hidden test set.\")\n",
    "\n",
    "recommended_uu_user3={idx for idx, score, name in uu_recs_user3}\n",
    "recommended_ii_user3={idx for idx, score, name in ii_recs_user3}\n",
    "\n",
    "hits_uu_user3=len(relevant_items_user3.intersection(recommended_uu_user3))\n",
    "precision_uu_user3 = hits_uu_user3 / 5\n",
    "recall_uu_user3 = hits_uu_user3 / num_relevant_user3 if num_relevant_user3 > 0 else 0\n",
    "\n",
    "print(\"\\n--- User-User CF Evaluation (User 3) ---\")\n",
    "print(f\"  Hits (correct recommendations): {hits_uu_user3} out of 5\")\n",
    "print(f\" Precision@5: {precision_uu_user3:.2f}\")\n",
    "print(f\"  Recall@5:  {recall_uu_user3:.2f}\")\n",
    "\n",
    "hits_ii_user3= len(relevant_items_user3.intersection(recommended_ii_user3))\n",
    "precision_ii_user3=hits_ii_user3 / 5\n",
    "recall_ii_user3 = hits_ii_user3 / num_relevant_user3 if num_relevant_user3 > 0 else 0\n",
    "\n",
    "print(\"\\n--- Item-Item CF Evaluation (User 3) ---\")\n",
    "print(f\" Hits (correct recommendations): {hits_ii_user3} out of 5\")\n",
    "print(f\" Precision@5: {precision_ii_user3:.2f}\")\n",
    "print(f\" Recall@5:  {recall_ii_user3:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titoconda2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
