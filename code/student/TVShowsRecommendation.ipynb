{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 1\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tv_recommendation import TVRecommendationEngine\n",
    "from evaluation_metrics import RecommendationEvaluator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape of R: (9985, 563)\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "engine = TVRecommendationEngine()\n",
    "# TODO: Load data\n",
    "engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "print(f\"shape of R: {engine.R.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "user degree matrix P has shape (9985, 9985)\n",
      "item degree matrix Q has shape: (563, 563)\n"
     ]
    }
   ],
   "source": [
    "# Cell 3\n",
    "# TODO: Preprocess data\n",
    "engine.preprocess_data()\n",
    "print(f\"user degree matrix P has shape {engine.P.shape}\")\n",
    "print(f\"item degree matrix Q has shape: {engine.Q.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "simulated missing data for user 499 Alex\n"
     ]
    }
   ],
   "source": [
    "# Cell 4\n",
    "ALEX_USER_ID = 499\n",
    "# TODO: Simulate missing data for first 100 shows\n",
    "missing_indices = list(range(100))\n",
    "\n",
    "R_alex_original = engine.R[ALEX_USER_ID, :].copy()\n",
    "engine.R[ALEX_USER_ID, missing_indices] = 0\n",
    "\n",
    "print(f\"simulated missing data for user {ALEX_USER_ID} Alex\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5\n",
    "# TODO: User-user collaborative filtering\n",
    "uu_scores = engine.user_user_collaborative_filtering(ALEX_USER_ID, missing_indices)\n",
    "uu_recommendations = engine.get_top_recommendations(uu_scores, missing_indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6\n",
    "# TODO: Item-item collaborative filtering\n",
    "ii_scores = engine.item_item_collaborative_filtering(ALEX_USER_ID, missing_indices)\n",
    "ii_recommendations = engine.get_top_recommendations(ii_scores, missing_indices, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User CF recommendations:\n",
      "1. \"FOX 28 News at 10pm\" (score: 908.48)\n",
      "2. \"Family Guy\" (score: 861.18)\n",
      "3. \"2009 NCAA Basketball Tournament\" (score: 827.60)\n",
      "4. \"NBC 4 at Eleven\" (score: 784.78)\n",
      "5. \"Two and a Half Men\" (score: 757.60)\n",
      "\n",
      "Item-Item CF recommendations:\n",
      "1. \"FOX 28 News at 10pm\" (score: 31.36)\n",
      "2. \"Family Guy\" (score: 30.00)\n",
      "3. \"NBC 4 at Eleven\" (score: 29.40)\n",
      "4. \"2009 NCAA Basketball Tournament\" (score: 29.23)\n",
      "5. \"Access Hollywood\" (score: 28.97)\n"
     ]
    }
   ],
   "source": [
    "# Cell 7\n",
    "# TODO: Display results\n",
    "print(\"User-User CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(uu_recommendations):\n",
    "    print(f\"{i+1}. {name} (score: {score:.2f})\")\n",
    "\n",
    "print(\"\\nItem-Item CF recommendations:\")\n",
    "for i, (idx, score, name) in enumerate(ii_recommendations):\n",
    "    print(f\"{i+1}. {name} (score: {score:.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User-User CF max score: 908.48 (requirement: > 900) ✓\n",
      "Item-Item CF max score: 31.36 (requirement: > 31) ✓\n",
      "All requirements passed!\n",
      "User-User recommendations: 5\n",
      "Item-Item recommendations: 5\n",
      "Overlap: 4\n",
      "Unique to User-User: 1\n",
      "Unique to Item-Item: 1\n",
      "Common recommendations:\n",
      "  - \"FOX 28 News at 10pm\"\n",
      "  - \"Family Guy\"\n",
      "  - \"2009 NCAA Basketball Tournament\"\n",
      "  - \"NBC 4 at Eleven\"\n",
      "\n",
      "Experiment Summary:\n",
      "Target User: 499 (Alex)\n",
      "Missing Items: First 100 shows\n",
      "User-User CF Max Score: 908.48\n",
      "Item-Item CF Max Score: 31.36\n",
      "Recommendations overlap: 4/5\n"
     ]
    }
   ],
   "source": [
    "# Cell 8\n",
    "evaluator = RecommendationEvaluator()\n",
    "\n",
    "uu_max_score = uu_recommendations[0][1] if uu_recommendations else 0\n",
    "ii_max_score = ii_recommendations[0][1] if ii_recommendations else 0\n",
    "evaluator.validate_requirements(uu_max_score, ii_max_score)\n",
    "overlap = evaluator.analyze_recommendations(uu_recommendations, ii_recommendations)\n",
    "\n",
    "\n",
    "print(f\"\\nExperiment Summary:\")\n",
    "print(f\"Target User: {ALEX_USER_ID} (Alex)\")\n",
    "print(f\"Missing Items: First 100 shows\")\n",
    "print(f\"User-User CF Max Score: {uu_max_score:.2f}\")\n",
    "print(f\"Item-Item CF Max Score: {ii_max_score:.2f}\")\n",
    "print(f\"Recommendations overlap: {len(overlap)}/5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset sparsity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Ratings matrix R has shape: (9985, 563)\n",
      "\n",
      "--- Dataset Sparsity Analysis ---\n",
      "Total ratings (1s): 758878\n",
      "Missing ratings (0s): 4862677\n",
      "Total possible ratings: 5621555\n",
      "Sparsity of the matrix: 86.50%\n"
     ]
    }
   ],
   "source": [
    "# Cell 2\n",
    "engine = TVRecommendationEngine()\n",
    "# TODO: Load data\n",
    "engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "print(f\"Data loaded successfully.\")\n",
    "print(f\"Ratings matrix R has shape: {engine.R.shape}\")\n",
    "\n",
    "# --- Code Snippet to Check Sparsity ---\n",
    "# Count the number of '1's (watched) in the matrix.\n",
    "num_ones = np.sum(engine.R)\n",
    "\n",
    "# Get the total number of elements in the matrix.\n",
    "total_elements = engine.R.size\n",
    "\n",
    "# Calculate the number of '0's (not watched).\n",
    "num_zeros = total_elements - num_ones\n",
    "\n",
    "# Calculate the sparsity of the matrix.\n",
    "sparsity = (num_zeros / total_elements) * 100\n",
    "\n",
    "print(f\"\\n--- Dataset Sparsity Analysis ---\")\n",
    "print(f\"Total ratings (1s): {num_ones}\")\n",
    "print(f\"Missing ratings (0s): {num_zeros}\")\n",
    "print(f\"Total possible ratings: {total_elements}\")\n",
    "print(f\"Sparsity of the matrix: {sparsity:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare Cosine Similairty Methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Verifying Cosine Similarity Calculations (with Refined Timing) ---\n",
      "\n",
      "Verification for User Similarity Matrix (Su):\n",
      "  Time taken (Our Formula):   37.7973 seconds\n",
      "  Time taken (sklearn):       1.8785 seconds\n",
      "  Maximum absolute difference:      2.11e-15\n",
      "\n",
      "Verification for Item Similarity Matrix (Si):\n",
      "  Time taken (Our Formula):   0.2271 seconds\n",
      "  Time taken (sklearn):       0.1126 seconds\n",
      "  Maximum absolute difference:      2.66e-15\n"
     ]
    }
   ],
   "source": [
    "# Cell for Verification with Refined Timing\n",
    "\n",
    "import time\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np # Make sure numpy is imported\n",
    "\n",
    "print(\"--- Verifying Cosine Similarity Calculations (with Refined Timing) ---\")\n",
    "\n",
    "# --- Setup: Do all data loading and preprocessing once ---\n",
    "temp_engine = TVRecommendationEngine()\n",
    "temp_engine.load_data('data/user-shows.txt', 'data/shows.txt')\n",
    "temp_engine.preprocess_data()\n",
    "R_matrix = temp_engine.R\n",
    "P_matrix = temp_engine.P\n",
    "Q_matrix = temp_engine.Q\n",
    "\n",
    "# --- 1. Verify User Similarity (Su) ---\n",
    "\n",
    "# Time our matrix formula\n",
    "start_time_formula = time.time()\n",
    "Su_formula = temp_engine.sim_computer.compute_user_similarity_matrix(R_matrix, P_matrix)\n",
    "end_time_formula = time.time()\n",
    "time_formula_user = end_time_formula - start_time_formula\n",
    "\n",
    "# Time the scikit-learn function\n",
    "start_time_sklearn = time.time()\n",
    "Su_sklearn = cosine_similarity(R_matrix)\n",
    "end_time_sklearn = time.time()\n",
    "time_sklearn_user = end_time_sklearn - start_time_sklearn\n",
    "\n",
    "# Calculate the difference for verification\n",
    "user_diff = np.abs(Su_formula - Su_sklearn)\n",
    "\n",
    "print(\"\\nVerification for User Similarity Matrix (Su):\")\n",
    "print(f\"  Time taken (Our Formula):   {time_formula_user:.4f} seconds\")\n",
    "print(f\"  Time taken (sklearn):       {time_sklearn_user:.4f} seconds\")\n",
    "print(f\"  Maximum absolute difference:      {np.max(user_diff):.2e}\")\n",
    "\n",
    "# --- 2. Verify Item Similarity (Si) ---\n",
    "\n",
    "# Time our matrix formula\n",
    "start_time_formula = time.time()\n",
    "Si_formula = temp_engine.sim_computer.compute_item_similarity_matrix(R_matrix, Q_matrix)\n",
    "end_time_formula = time.time()\n",
    "time_formula_item = end_time_formula - start_time_formula\n",
    "\n",
    "# Time the scikit-learn function\n",
    "start_time_sklearn = time.time()\n",
    "Si_sklearn = cosine_similarity(R_matrix.T)\n",
    "end_time_sklearn = time.time()\n",
    "time_sklearn_item = end_time_sklearn - start_time_sklearn\n",
    "\n",
    "# Calculate the difference for verification\n",
    "item_diff = np.abs(Si_formula - Si_sklearn)\n",
    "\n",
    "print(\"\\nVerification for Item Similarity Matrix (Si):\")\n",
    "print(f\"  Time taken (Our Formula):   {time_formula_item:.4f} seconds\")\n",
    "print(f\"  Time taken (sklearn):       {time_sklearn_item:.4f} seconds\")\n",
    "print(f\"  Maximum absolute difference:      {np.max(item_diff):.2e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "titoconda2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
